{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd09fead",
   "metadata": {},
   "source": [
    "# ECG Image to Time-Series Deep Learning Pipeline\n",
    "## High-Performance 12-Lead ECG Signal Extraction with SNR Optimization\n",
    "\n",
    "**Objective**: Extract 12-lead ECG time-series from images using deep learning.\n",
    "### Key Features:\n",
    "- Multi-task deep learning with artifact correction\n",
    "- Automated lead detection and deskewing\n",
    "- Precise calibration and physical unit conversion\n",
    "- Optimal resampling to fixed sampling rate (500 Hz)\n",
    "- SNR-optimized evaluation with cross-correlation\n",
    "- Robustness testing for various artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45658c28",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f3a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported!\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from scipy import ndimage, interpolate, signal\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from skimage import filters, morphology, measure, transform\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Utilities\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "print(\"✓ All libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b5fb9",
   "metadata": {},
   "source": [
    "## ECGDataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827bcb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class_name = \"ECGDataLoader\"\n",
    "\n",
    "class ECGDataLoader:\n",
    "    \"\"\"Load and preprocess ECG images and ground truth time-series data\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_dir: str,\n",
    "                 csv_dir: str,\n",
    "                 target_size: Tuple[int, int] = (1024, 512),\n",
    "                 sampling_rate: float = 500.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir: Directory containing ECG images\n",
    "            csv_dir: Directory containing ground truth CSV files\n",
    "            target_size: Resize images to this size (height, width)\n",
    "            sampling_rate: Standard sampling rate in Hz\n",
    "        \"\"\"\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.csv_dir = Path(csv_dir)\n",
    "        self.target_size = target_size\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "    def load_image(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Load and normalize ECG image\"\"\"\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "\n",
    "        # Normalize to [0, 1]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        # Resize to target size\n",
    "        img = cv2.resize(img, (self.target_size[1], self.target_size[0]))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def load_ground_truth(self, csv_path: str) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Load 12-lead ground truth time series from CSV\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Assume CSV has columns: time, lead_I, lead_II, ..., lead_aVF\n",
    "        leads = {}\n",
    "        lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "\n",
    "        for lead_name in lead_names:\n",
    "            if f'lead_{lead_name}' in df.columns:\n",
    "                leads[lead_name] = df[f'lead_{lead_name}'].values\n",
    "\n",
    "        time = df['time'].values if 'time' in df.columns else np.arange(len(df)) / self.sampling_rate\n",
    "\n",
    "        return {'time': time, 'leads': leads}\n",
    "\n",
    "    def normalize_image(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply adaptive histogram equalization for contrast enhancement\"\"\"\n",
    "        if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "            img_eq = equalize_adapthist(img, clip_limit=0.03)\n",
    "            return img_eq\n",
    "        return img\n",
    "\n",
    "    def augment_image(self, img: np.ndarray,\n",
    "                     rotation_range: float = 5.0,\n",
    "                     noise_std: float = 0.02) -> np.ndarray:\n",
    "        \"\"\"Apply augmentation: rotation and Gaussian noise\"\"\"\n",
    "        # Random rotation\n",
    "        angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "        img = transform.rotate(img, angle, preserve_range=True)\n",
    "\n",
    "        # Add Gaussian noise\n",
    "        noise = np.random.normal(0, noise_std, img.shape)\n",
    "        img = np.clip(img + noise, 0, 1)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def create_dataset_summary(self) -> Dict:\n",
    "        \"\"\"Create a summary of available data\"\"\"\n",
    "        images = list(self.image_dir.glob('*.jpg')) + list(self.image_dir.glob('*.png'))\n",
    "        csvs = list(self.csv_dir.glob('*.csv'))\n",
    "\n",
    "        summary = {\n",
    "            'num_images': len(images),\n",
    "            'num_csvs': len(csvs),\n",
    "            'image_files': [str(f) for f in images[:5]],  # First 5\n",
    "            'csv_files': [str(f) for f in csvs[:5]],  # First 5\n",
    "        }\n",
    "        return summary\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f5643",
   "metadata": {},
   "source": [
    "## GridAndNoiseFilter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141db770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class GridAndNoiseFilter:\n",
    "    \"\"\"Suppress background grid and extract only ECG signal lines\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 morphology_kernel_size: int = 3,\n",
    "                 blur_kernel_size: int = 5):\n",
    "        self.morphology_kernel_size = morphology_kernel_size\n",
    "        self.blur_kernel_size = blur_kernel_size\n",
    "\n",
    "    def filter_grid_opencv(self, img: np.ndarray,\n",
    "                          threshold: float = 0.3) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Remove background grid using morphological operations.\n",
    "        Isolates thin ECG signal lines while suppressing thick grid lines.\n",
    "        \"\"\"\n",
    "        # Convert to 0-255 range for OpenCV\n",
    "        img_cv = (img * 255).astype(np.uint8)\n",
    "\n",
    "        # Apply adaptive thresholding to separate signal from background\n",
    "        binary = cv2.adaptiveThreshold(img_cv, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        # Remove small noise components\n",
    "        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small)\n",
    "\n",
    "        # Dilate to connect signal lines\n",
    "        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        binary = cv2.dilate(binary, kernel_dilate, iterations=1)\n",
    "\n",
    "        # Extract thin lines (ECG signal) by eroding and checking connectivity\n",
    "        kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        eroded = cv2.erode(binary, kernel_erode, iterations=1)\n",
    "\n",
    "        # Keep only well-connected components (signal lines)\n",
    "        num_labels, labels = cv2.connectedComponents(eroded)\n",
    "\n",
    "        signal_mask = np.zeros_like(eroded)\n",
    "        for label in range(1, num_labels):\n",
    "            component = (labels == label)\n",
    "            area = component.sum()\n",
    "\n",
    "            # Keep components with reasonable size (signal lines, not noise or thick grid)\n",
    "            if 100 < area < 100000:  # Adjust based on image size\n",
    "                signal_mask |= component.astype(np.uint8)\n",
    "\n",
    "        return signal_mask.astype(np.float32) / 255.0\n",
    "\n",
    "    def filter_grid_morphology(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Use morphological reconstruction to remove grid.\n",
    "        Preserves thin signal lines while removing thick grid lines.\n",
    "        \"\"\"\n",
    "        # Binary threshold\n",
    "        binary = img > filters.threshold_otsu(img)\n",
    "\n",
    "        # Morphological opening to remove small noise\n",
    "        opened = morphology.opening(binary, morphology.disk(1))\n",
    "\n",
    "        # Identify thick structures (grid lines) vs thin structures (signal)\n",
    "        # Use horizontal and vertical closing to identify grid\n",
    "        h_kernel = morphology.line(3, angle=0, shape=np.uint8)\n",
    "        v_kernel = morphology.line(3, angle=90, shape=np.uint8)\n",
    "\n",
    "        h_lines = morphology.closing(opened, h_kernel)\n",
    "        v_lines = morphology.closing(opened, v_kernel)\n",
    "\n",
    "        grid_estimate = h_lines | v_lines\n",
    "\n",
    "        # Remove grid from original\n",
    "        signal_only = opened & ~grid_estimate\n",
    "\n",
    "        return signal_only.astype(np.float32)\n",
    "\n",
    "    def denoise_signal(self, img: np.ndarray,\n",
    "                      method: str = 'bilateral') -> np.ndarray:\n",
    "        \"\"\"Denoise while preserving signal edges\"\"\"\n",
    "        img_cv = (img * 255).astype(np.uint8)\n",
    "\n",
    "        if method == 'bilateral':\n",
    "            # Bilateral filter preserves edges\n",
    "            denoised = cv2.bilateralFilter(img_cv, 5, 50, 50)\n",
    "        elif method == 'median':\n",
    "            denoised = cv2.medianBlur(img_cv, 5)\n",
    "        else:\n",
    "            denoised = img_cv\n",
    "\n",
    "        return denoised.astype(np.float32) / 255.0\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec0e07",
   "metadata": {},
   "source": [
    "## LeadLocalizationAndDeskew Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e762a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class LeadLocalizationAndDeskew:\n",
    "    \"\"\"Detect lead bounding boxes, calibration marks, and correct image rotation\"\"\"\n",
    "\n",
    "    def __init__(self, num_leads: int = 12):\n",
    "        self.num_leads = num_leads\n",
    "\n",
    "    def estimate_rotation_angle(self, signal_mask: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Estimate image rotation using Hough transform on signal lines.\n",
    "        Returns rotation angle in degrees.\n",
    "        \"\"\"\n",
    "        # Find edges in signal mask\n",
    "        edges = cv2.Canny((signal_mask * 255).astype(np.uint8), 50, 150)\n",
    "\n",
    "        # Hough line transform\n",
    "        lines = cv2.HoughLines(edges, rho=1, theta=np.pi/180, threshold=50)\n",
    "\n",
    "        if lines is None or len(lines) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # Extract angles and find median (robust to outliers)\n",
    "        angles = []\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            angle_deg = np.degrees(theta)\n",
    "\n",
    "            # Normalize angle to [-90, 90] range\n",
    "            if angle_deg > 90:\n",
    "                angle_deg -= 180\n",
    "            angles.append(angle_deg)\n",
    "\n",
    "        # Median angle is most robust\n",
    "        median_angle = np.median(angles)\n",
    "\n",
    "        return median_angle\n",
    "\n",
    "    def deskew_image(self, img: np.ndarray,\n",
    "                    rotation_angle: Optional[float] = None) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Deskew image to straighten tilted ECG.\n",
    "        If rotation_angle not provided, it's estimated from the image.\n",
    "        \"\"\"\n",
    "        # Estimate angle if not provided\n",
    "        if rotation_angle is None:\n",
    "            # Simple edge detection and Hough\n",
    "            edges = cv2.Canny((img * 255).astype(np.uint8), 50, 150)\n",
    "            rotation_angle = self.estimate_rotation_angle(edges)\n",
    "\n",
    "        # Apply affine transformation\n",
    "        h, w = img.shape\n",
    "        center = (w / 2, h / 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "        deskewed = cv2.warpAffine(img, rotation_matrix, (w, h),\n",
    "                                  borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "        return deskewed, rotation_angle\n",
    "\n",
    "    def detect_lead_bboxes(self, signal_mask: np.ndarray,\n",
    "                          num_leads: int = 12) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Detect bounding boxes for each lead using connected components.\n",
    "        Assumes leads are roughly horizontal and arranged vertically.\n",
    "        \"\"\"\n",
    "        # Label connected components\n",
    "        num_labels, labels = cv2.connectedComponents((signal_mask * 255).astype(np.uint8))\n",
    "\n",
    "        bboxes = []\n",
    "        for label in range(1, num_labels):\n",
    "            component = (labels == label)\n",
    "            y_coords, x_coords = np.where(component)\n",
    "\n",
    "            if len(y_coords) > 0:\n",
    "                bbox = {\n",
    "                    'label_id': label,\n",
    "                    'x_min': int(x_coords.min()),\n",
    "                    'y_min': int(y_coords.min()),\n",
    "                    'x_max': int(x_coords.max()),\n",
    "                    'y_max': int(y_coords.max()),\n",
    "                    'width': int(x_coords.max() - x_coords.min()),\n",
    "                    'height': int(y_coords.max() - y_coords.min()),\n",
    "                    'area': len(y_coords)\n",
    "                }\n",
    "                bboxes.append(bbox)\n",
    "\n",
    "        # Sort by y-coordinate (top to bottom)\n",
    "        bboxes.sort(key=lambda b: b['y_min'])\n",
    "\n",
    "        # Keep top num_leads bboxes by area\n",
    "        bboxes = sorted(bboxes, key=lambda b: b['area'], reverse=True)[:num_leads]\n",
    "        bboxes.sort(key=lambda b: b['y_min'])\n",
    "\n",
    "        return bboxes\n",
    "\n",
    "    def detect_calibration_marks(self, img: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect 1 mV vertical and 0.2 s horizontal calibration marks.\n",
    "        Typically located at bottom-right corner.\n",
    "        \"\"\"\n",
    "        h, w = img.shape\n",
    "\n",
    "        # Search in bottom-right corner region\n",
    "        roi_h = h // 4\n",
    "        roi_w = w // 4\n",
    "        roi = img[h - roi_h:h, w - roi_w:w]\n",
    "\n",
    "        # Find bright rectangular regions (calibration marks)\n",
    "        binary = roi > filters.threshold_otsu(roi)\n",
    "\n",
    "        # Label components\n",
    "        num_labels, labels = cv2.connectedComponents(binary.astype(np.uint8))\n",
    "\n",
    "        calibration_marks = []\n",
    "        for label in range(1, num_labels):\n",
    "            component = (labels == label)\n",
    "            y_coords, x_coords = np.where(component)\n",
    "\n",
    "            if 50 < len(y_coords) < 5000:  # Reasonable size for calibration mark\n",
    "                mark = {\n",
    "                    'x_min': x_coords.min() + w - roi_w,\n",
    "                    'y_min': y_coords.min() + h - roi_h,\n",
    "                    'x_max': x_coords.max() + w - roi_w,\n",
    "                    'y_max': y_coords.max() + h - roi_h,\n",
    "                    'width': x_coords.max() - x_coords.min(),\n",
    "                    'height': y_coords.max() - y_coords.min(),\n",
    "                }\n",
    "                calibration_marks.append(mark)\n",
    "\n",
    "        return {\n",
    "            'num_marks': len(calibration_marks),\n",
    "            'marks': calibration_marks\n",
    "        }\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7db583",
   "metadata": {},
   "source": [
    "## SignalTraceExtractor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3940e5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class SignalTraceExtractor:\n",
    "    \"\"\"Extract pixel coordinates of ECG signal traces using line following\"\"\"\n",
    "\n",
    "    def __init__(self, centerline_method: str = 'dynamic_programming'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            centerline_method: 'dynamic_programming', 'a_star', or 'viterbi'\n",
    "        \"\"\"\n",
    "        self.centerline_method = centerline_method\n",
    "\n",
    "    def extract_trace_viterbi(self, signal_mask: np.ndarray,\n",
    "                             bbox: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract signal trace using Viterbi algorithm.\n",
    "        Models the signal path as a hidden Markov model.\n",
    "\n",
    "        Returns: array of shape (width, 2) with [x, y] pixel coordinates\n",
    "        \"\"\"\n",
    "        x_min, x_max = bbox['x_min'], bbox['x_max']\n",
    "        y_min, y_max = bbox['y_min'], bbox['y_max']\n",
    "\n",
    "        # Extract ROI\n",
    "        roi = signal_mask[y_min:y_max+1, x_min:x_max+1]\n",
    "        roi_h, roi_w = roi.shape\n",
    "\n",
    "        if roi_w < 2:\n",
    "            return np.array([])\n",
    "\n",
    "        # Initialize probability matrix (log space for numerical stability)\n",
    "        # Rows: y-position, Cols: x-position\n",
    "        log_prob = np.full((roi_h, roi_w), -np.inf)\n",
    "        path_tracker = np.zeros((roi_h, roi_w), dtype=int)\n",
    "\n",
    "        # Emission probabilities from signal mask\n",
    "        emission = np.log(roi + 1e-6)\n",
    "\n",
    "        # Initialize first column\n",
    "        log_prob[:, 0] = emission[:, 0]\n",
    "\n",
    "        # Forward pass (Viterbi)\n",
    "        for x in range(1, roi_w):\n",
    "            for y in range(roi_h):\n",
    "                # Consider transitions from previous column (y-1, y, y+1)\n",
    "                candidates = []\n",
    "                for prev_y in range(max(0, y-1), min(roi_h, y+2)):\n",
    "                    candidates.append(log_prob[prev_y, x-1])\n",
    "\n",
    "                max_prob = max(candidates)\n",
    "                best_prev_y = max(0, y-1) + np.argmax(candidates)\n",
    "\n",
    "                log_prob[y, x] = max_prob + emission[y, x]\n",
    "                path_tracker[y, x] = best_prev_y\n",
    "\n",
    "        # Backtrack to find best path\n",
    "        trace = []\n",
    "        current_y = np.argmax(log_prob[:, -1])\n",
    "\n",
    "        for x in range(roi_w - 1, -1, -1):\n",
    "            trace.append([x + x_min, current_y + y_min])\n",
    "            if x > 0:\n",
    "                current_y = path_tracker[current_y, x]\n",
    "\n",
    "        trace = np.array(trace[::-1])  # Reverse to get left-to-right order\n",
    "\n",
    "        return trace\n",
    "\n",
    "    def extract_trace_dynamic_programming(self, signal_mask: np.ndarray,\n",
    "                                         bbox: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract centerline of signal using dynamic programming.\n",
    "        Minimizes vertical distance traveled while staying on signal.\n",
    "        \"\"\"\n",
    "        x_min, x_max = bbox['x_min'], bbox['x_max']\n",
    "        y_min, y_max = bbox['y_min'], bbox['y_max']\n",
    "\n",
    "        # Extract ROI\n",
    "        roi = signal_mask[y_min:y_max+1, x_min:x_max+1]\n",
    "        roi_h, roi_w = roi.shape\n",
    "\n",
    "        if roi_w < 2:\n",
    "            return np.array([])\n",
    "\n",
    "        # Cost matrix: prefer staying on signal (low cost where signal is bright)\n",
    "        cost = 1.0 - roi\n",
    "\n",
    "        # Initialize DP table\n",
    "        dp = np.full((roi_h, roi_w), np.inf)\n",
    "        dp[:, 0] = cost[:, 0]\n",
    "        parent = np.zeros((roi_h, roi_w), dtype=int)\n",
    "\n",
    "        # Forward pass\n",
    "        for x in range(1, roi_w):\n",
    "            for y in range(roi_h):\n",
    "                # Consider transitions: y-1, y, y+1 from previous column\n",
    "                for prev_y in range(max(0, y-2), min(roi_h, y+3)):\n",
    "                    transition_cost = dp[prev_y, x-1] + abs(y - prev_y) * 0.5\n",
    "                    new_cost = transition_cost + cost[y, x]\n",
    "\n",
    "                    if new_cost < dp[y, x]:\n",
    "                        dp[y, x] = new_cost\n",
    "                        parent[y, x] = prev_y\n",
    "\n",
    "        # Backtrack\n",
    "        trace = []\n",
    "        current_y = np.argmin(dp[:, -1])\n",
    "\n",
    "        for x in range(roi_w - 1, -1, -1):\n",
    "            trace.append([x + x_min, current_y + y_min])\n",
    "            if x > 0:\n",
    "                current_y = parent[current_y, x]\n",
    "\n",
    "        trace = np.array(trace[::-1])\n",
    "\n",
    "        return trace\n",
    "\n",
    "    def extract_trace_centerline(self, signal_mask: np.ndarray,\n",
    "                                bbox: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract centerline by finding the brightest vertical slice at each x.\n",
    "        Simple but effective for well-defined signals.\n",
    "        \"\"\"\n",
    "        x_min, x_max = bbox['x_min'], bbox['x_max']\n",
    "        y_min, y_max = bbox['y_min'], bbox['y_max']\n",
    "\n",
    "        # Extract ROI\n",
    "        roi = signal_mask[y_min:y_max+1, x_min:x_max+1]\n",
    "        roi_h, roi_w = roi.shape\n",
    "\n",
    "        trace = []\n",
    "        for x in range(roi_w):\n",
    "            col = roi[:, x]\n",
    "            if col.sum() > 0:\n",
    "                # Center of mass in y\n",
    "                y_coords = np.arange(roi_h)\n",
    "                y_center = np.average(y_coords, weights=col)\n",
    "                trace.append([x + x_min, int(y_center + y_min)])\n",
    "            else:\n",
    "                # Interpolate from neighbors\n",
    "                if len(trace) > 0:\n",
    "                    trace.append([x + x_min, trace[-1][1]])\n",
    "\n",
    "        return np.array(trace)\n",
    "\n",
    "    def smooth_trace(self, trace: np.ndarray, window_size: int = 5) -> np.ndarray:\n",
    "        \"\"\"Apply Savitzky-Golay filter to smooth trace while preserving edges\"\"\"\n",
    "        if len(trace) < window_size:\n",
    "            return trace\n",
    "\n",
    "        from scipy.signal import savgol_filter\n",
    "\n",
    "        smoothed_x = savgol_filter(trace[:, 0], window_size, 2)\n",
    "        smoothed_y = savgol_filter(trace[:, 1], window_size, 2)\n",
    "\n",
    "        return np.column_stack([smoothed_x, smoothed_y])\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89191eef",
   "metadata": {},
   "source": [
    "## CalibrationAndScaling Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80ece051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class CalibrationAndScaling:\n",
    "    \"\"\"\n",
    "    Identify calibration marks and convert pixel coordinates to physical units.\n",
    "    Standard ECG calibration: 1 mV (vertical), 0.2 s (horizontal)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 mv_mark_height: float = 1.0,  # millivolts\n",
    "                 time_mark_width: float = 0.2):  # seconds\n",
    "        self.mv_mark_height = mv_mark_height\n",
    "        self.time_mark_width = time_mark_width\n",
    "\n",
    "    def detect_vertical_calibration(self, img: np.ndarray) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Detect the vertical 1 mV calibration mark.\n",
    "        Returns pixel height corresponding to 1 mV.\n",
    "        \"\"\"\n",
    "        h, w = img.shape\n",
    "\n",
    "        # Search in bottom-right corner\n",
    "        roi_h = h // 5\n",
    "        roi_w = w // 8\n",
    "        roi = img[h - roi_h:h, w - roi_w:w]\n",
    "\n",
    "        # Find rectangular bright region\n",
    "        binary = roi > filters.threshold_otsu(roi)\n",
    "\n",
    "        # Label components\n",
    "        num_labels, labels = cv2.connectedComponents(binary.astype(np.uint8))\n",
    "\n",
    "        for label in range(1, num_labels):\n",
    "            component = (labels == label)\n",
    "            y_coords, x_coords = np.where(component)\n",
    "\n",
    "            if len(y_coords) > 20:  # Reasonable size\n",
    "                mark_height = y_coords.max() - y_coords.min()\n",
    "\n",
    "                # Vertical calibration mark should be taller than wide\n",
    "                if mark_height > x_coords.max() - x_coords.min():\n",
    "                    return float(mark_height)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def detect_horizontal_calibration(self, img: np.ndarray) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Detect the horizontal 0.2 s calibration mark.\n",
    "        Returns pixel width corresponding to 0.2 s.\n",
    "        \"\"\"\n",
    "        h, w = img.shape\n",
    "\n",
    "        # Search in bottom-right corner\n",
    "        roi_h = h // 5\n",
    "        roi_w = w // 8\n",
    "        roi = img[h - roi_h:h, w - roi_w:w]\n",
    "\n",
    "        # Find rectangular bright region\n",
    "        binary = roi > filters.threshold_otsu(roi)\n",
    "\n",
    "        # Label components\n",
    "        num_labels, labels = cv2.connectedComponents(binary.astype(np.uint8))\n",
    "\n",
    "        for label in range(1, num_labels):\n",
    "            component = (labels == label)\n",
    "            y_coords, x_coords = np.where(component)\n",
    "\n",
    "            if len(x_coords) > 20:  # Reasonable size\n",
    "                mark_width = x_coords.max() - x_coords.min()\n",
    "\n",
    "                # Horizontal calibration mark should be wider than tall\n",
    "                if mark_width > y_coords.max() - y_coords.min():\n",
    "                    return float(mark_width)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def estimate_calibration_factors(self,\n",
    "                                     img: np.ndarray,\n",
    "                                     sampling_rate: float = 500.0) -> Dict:\n",
    "        \"\"\"\n",
    "        Estimate pixel-to-physical conversion factors.\n",
    "        If calibration marks not found, estimate from image dimensions.\n",
    "        \"\"\"\n",
    "        h, w = img.shape\n",
    "\n",
    "        # Detect calibration marks\n",
    "        v_calib = self.detect_vertical_calibration(img)\n",
    "        h_calib = self.detect_horizontal_calibration(img)\n",
    "\n",
    "        # If not detected, estimate from image aspect ratio\n",
    "        if v_calib is None:\n",
    "            # Assume typical ECG dimensions\n",
    "            v_calib = h / 10  # Rough estimate\n",
    "\n",
    "        if h_calib is None:\n",
    "            # Typical ECG time window: 10 seconds -> 5000 pixels\n",
    "            estimated_duration = 10.0\n",
    "            h_calib = w * (self.time_mark_width / estimated_duration)\n",
    "\n",
    "        # Calculate conversion factors\n",
    "        pixels_per_mv = v_calib / self.mv_mark_height\n",
    "        pixels_per_second = h_calib / self.time_mark_width\n",
    "\n",
    "        return {\n",
    "            'pixels_per_mv': pixels_per_mv,\n",
    "            'pixels_per_second': pixels_per_second,\n",
    "            'mv_per_pixel': self.mv_mark_height / v_calib,\n",
    "            'seconds_per_pixel': self.time_mark_width / h_calib,\n",
    "            'sampling_rate': sampling_rate,\n",
    "        }\n",
    "\n",
    "    def pixel_to_physical(self,\n",
    "                         traces: Dict[str, np.ndarray],\n",
    "                         calibration: Dict,\n",
    "                         img_width: int) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Convert pixel coordinates to physical units (time, amplitude).\n",
    "\n",
    "        Args:\n",
    "            traces: Dict with lead names as keys, traces as values (Nx2 arrays)\n",
    "            calibration: Calibration factors from estimate_calibration_factors\n",
    "            img_width: Image width in pixels\n",
    "\n",
    "        Returns:\n",
    "            Dict with lead names as keys, physical traces (Nx2 arrays) as values\n",
    "        \"\"\"\n",
    "        physical_traces = {}\n",
    "\n",
    "        pixels_per_second = calibration['pixels_per_second']\n",
    "        mv_per_pixel = calibration['mv_per_pixel']\n",
    "\n",
    "        for lead_name, trace in traces.items():\n",
    "            if len(trace) == 0:\n",
    "                physical_traces[lead_name] = np.array([])\n",
    "                continue\n",
    "\n",
    "            # Convert x (pixels) to time (seconds)\n",
    "            x_pixels = trace[:, 0]\n",
    "            time = x_pixels / pixels_per_second\n",
    "\n",
    "            # Convert y (pixels) to amplitude (mV)\n",
    "            y_pixels = trace[:, 1]\n",
    "            # Invert y-axis (top is negative, bottom is positive in ECG)\n",
    "            y_pixels_inverted = -y_pixels + np.mean(y_pixels)\n",
    "            amplitude = y_pixels_inverted * mv_per_pixel\n",
    "\n",
    "            physical_traces[lead_name] = np.column_stack([time, amplitude])\n",
    "\n",
    "        return physical_traces\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87a8d2",
   "metadata": {},
   "source": [
    "## TimeSeriesResampler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15085ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesResampler:\n",
    "    \"\"\"Resample unevenly spaced time-series to fixed sampling rate using interpolation\"\"\"\n",
    "\n",
    "    def __init__(self, target_sampling_rate: float = 500.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            target_sampling_rate: Target sampling frequency in Hz\n",
    "        \"\"\"\n",
    "        self.target_sampling_rate = target_sampling_rate\n",
    "\n",
    "    def resample_cubic_spline(self,\n",
    "                             time: np.ndarray,\n",
    "                             amplitude: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Resample using cubic spline interpolation.\n",
    "\n",
    "        Args:\n",
    "            time: Time points (may be unevenly spaced)\n",
    "            amplitude: Signal amplitude values\n",
    "\n",
    "        Returns:\n",
    "            Resampled amplitude values at fixed sampling rate\n",
    "        \"\"\"\n",
    "        if len(time) < 4:  # Need at least 4 points for cubic spline\n",
    "            return np.array([])\n",
    "\n",
    "        # Create cubic spline\n",
    "        try:\n",
    "            spline = CubicSpline(time, amplitude, bc_type='natural')\n",
    "        except Exception as e:\n",
    "            print(f\"Spline creation failed: {e}, using linear interpolation\")\n",
    "            spline = interp1d(time, amplitude, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "        # Generate new time grid\n",
    "        t_start = time.min()\n",
    "        t_end = time.max()\n",
    "        n_samples = int((t_end - t_start) * self.target_sampling_rate) + 1\n",
    "\n",
    "        new_time = np.linspace(t_start, t_end, n_samples)\n",
    "\n",
    "        # Interpolate\n",
    "        new_amplitude = spline(new_time)\n",
    "\n",
    "        return new_amplitude\n",
    "\n",
    "    def resample_linear(self,\n",
    "                       time: np.ndarray,\n",
    "                       amplitude: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Resample using linear interpolation (faster, less smooth)\"\"\"\n",
    "        if len(time) < 2:\n",
    "            return np.array([])\n",
    "\n",
    "        interp_func = interp1d(time, amplitude, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "        t_start = time.min()\n",
    "        t_end = time.max()\n",
    "        n_samples = int((t_end - t_start) * self.target_sampling_rate) + 1\n",
    "\n",
    "        new_time = np.linspace(t_start, t_end, n_samples)\n",
    "        new_amplitude = interp_func(new_time)\n",
    "\n",
    "        return new_amplitude\n",
    "\n",
    "    def resample_all_leads(self,\n",
    "                          physical_traces: Dict[str, np.ndarray],\n",
    "                          method: str = 'cubic') -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Resample all leads to fixed sampling rate.\n",
    "\n",
    "        Args:\n",
    "            physical_traces: Dict with lead names, values are (Nx2) arrays [time, amplitude]\n",
    "            method: 'cubic' or 'linear'\n",
    "\n",
    "        Returns:\n",
    "            Dict with lead names, values are resampled amplitudes\n",
    "        \"\"\"\n",
    "        resampled_leads = {}\n",
    "\n",
    "        for lead_name, trace in physical_traces.items():\n",
    "            if len(trace) < 2:\n",
    "                resampled_leads[lead_name] = np.array([])\n",
    "                continue\n",
    "\n",
    "            time = trace[:, 0]\n",
    "            amplitude = trace[:, 1]\n",
    "\n",
    "            if method == 'cubic':\n",
    "                resampled = self.resample_cubic_spline(time, amplitude)\n",
    "            else:\n",
    "                resampled = self.resample_linear(time, amplitude)\n",
    "\n",
    "            resampled_leads[lead_name] = resampled\n",
    "\n",
    "        return resampled_leads\n",
    "\n",
    "    def validate_resampled_length(self,\n",
    "                                 resampled_leads: Dict[str, np.ndarray],\n",
    "                                 target_length: Optional[int] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Validate that all leads have been resampled to the same length.\n",
    "        If target_length provided, ensure all match that length.\n",
    "        \"\"\"\n",
    "        lengths = [len(v) for v in resampled_leads.values() if len(v) > 0]\n",
    "\n",
    "        if len(set(lengths)) > 1:\n",
    "            print(f\"Warning: Inconsistent resampled lengths: {set(lengths)}\")\n",
    "            return False\n",
    "\n",
    "        if target_length is not None and len(lengths) > 0:\n",
    "            if lengths[0] != target_length:\n",
    "                print(f\"Warning: Expected length {target_length}, got {lengths[0]}\")\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "class ECGSegmentationHead(nn.Module):\n",
    "    \"\"\"U-Net style decoder for grid/noise filtering segmentation\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int = 512, out_channels: int = 1):\n",
    "        super().__init__()\n",
    "        self.up1 = nn.ConvTranspose2d(in_channels, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.up3 = nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(16, 8, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(8, out_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.up3(x)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ECGDetectionHead(nn.Module):\n",
    "    \"\"\"YOLO-style object detection head for lead and calibration mark detection\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int = 512, num_leads: int = 12):\n",
    "        super().__init__()\n",
    "        self.num_leads = num_leads\n",
    "\n",
    "        # Bounding box regression\n",
    "        self.bbox_predictor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_leads * 4)  # 4 coords per lead\n",
    "        )\n",
    "\n",
    "        # Confidence scores\n",
    "        self.confidence_predictor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_leads),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bboxes = self.bbox_predictor(x)\n",
    "        confidences = self.confidence_predictor(x)\n",
    "\n",
    "        bboxes = bboxes.view(-1, self.num_leads, 4)\n",
    "\n",
    "        return bboxes, confidences\n",
    "\n",
    "\n",
    "class ECGRegressionHead(nn.Module):\n",
    "    \"\"\"Temporal regression head for signal trace prediction\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int = 512, sequence_length: int = 1024):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(in_channels, 256, num_layers=2, batch_first=True,\n",
    "                           bidirectional=True, dropout=0.3)\n",
    "\n",
    "        # Regression layers\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, sequence_length)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape for LSTM: (batch, sequence, features)\n",
    "        batch_size, channels, height, width = x.shape\n",
    "\n",
    "        # Flatten spatial dimensions into sequence\n",
    "        x = x.view(batch_size, channels, -1)  # (batch, channels, height*width)\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, channels)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Take last output\n",
    "        lstm_features = lstm_out[:, -1, :]\n",
    "\n",
    "        signal_trace = self.regression_head(lstm_features)\n",
    "\n",
    "        return signal_trace\n",
    "\n",
    "\n",
    "class MultiTaskECGModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-task deep learning model for ECG image analysis.\n",
    "\n",
    "    Tasks:\n",
    "    1. Grid/Noise filtering (segmentation)\n",
    "    2. Lead localization (object detection)\n",
    "    3. Signal trace extraction (regression)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 backbone: str = 'resnet34',\n",
    "                 num_leads: int = 12,\n",
    "                 sequence_length: int = 1024,\n",
    "                 pretrained: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_leads = num_leads\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        # Input adaptation for grayscale images (1 channel -> 3 channels)\n",
    "        self.input_adapter = nn.Conv2d(1, 3, kernel_size=1, bias=False)\n",
    "\n",
    "        # Feature extraction backbone\n",
    "        if backbone == 'resnet34':\n",
    "            self.backbone = models.resnet34(pretrained=pretrained)\n",
    "            backbone_out_channels = 512\n",
    "        elif backbone == 'resnet50':\n",
    "            self.backbone = models.resnet50(pretrained=pretrained)\n",
    "            backbone_out_channels = 2048\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
    "\n",
    "        # Remove classification head\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "\n",
    "        # Task heads\n",
    "        self.segmentation_head = ECGSegmentationHead(backbone_out_channels, out_channels=1)\n",
    "        self.detection_head = ECGDetectionHead(backbone_out_channels, num_leads=num_leads)\n",
    "        self.regression_head = ECGRegressionHead(backbone_out_channels, sequence_length=sequence_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input image tensor (batch, 1, height, width)\n",
    "\n",
    "        Returns:\n",
    "            segmentation_mask: (batch, 1, H, W)\n",
    "            bboxes: (batch, num_leads, 4)\n",
    "            confidences: (batch, num_leads)\n",
    "            signal_traces: (batch, sequence_length)\n",
    "        \"\"\"\n",
    "        # Adapt input from 1 channel to 3 channels\n",
    "        x = self.input_adapter(x)\n",
    "\n",
    "        # Extract features\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # Task-specific heads\n",
    "        segmentation_mask = self.segmentation_head(features)\n",
    "        bboxes, confidences = self.detection_head(features)\n",
    "        signal_traces = self.regression_head(features)\n",
    "\n",
    "        return {\n",
    "            'segmentation': segmentation_mask,\n",
    "            'bboxes': bboxes,\n",
    "            'confidences': confidences,\n",
    "            'signal_traces': signal_traces\n",
    "        }\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice coefficient loss for segmentation\"\"\"\n",
    "\n",
    "    def __init__(self, smooth: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: (batch, 1, H, W) with values in [0, 1]\n",
    "            targets: (batch, 1, H, W) binary targets\n",
    "        \"\"\"\n",
    "        intersection = (predictions * targets).sum()\n",
    "        union = predictions.sum() + targets.sum()\n",
    "\n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        return 1.0 - dice\n",
    "\n",
    "\n",
    "class JaccardLoss(nn.Module):\n",
    "    \"\"\"Jaccard (IoU) loss for segmentation\"\"\"\n",
    "\n",
    "    def __init__(self, smooth: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"IoU = Intersection / Union\"\"\"\n",
    "        intersection = (predictions * targets).sum()\n",
    "        union = (predictions + targets - predictions * targets).sum()\n",
    "\n",
    "        iou = (intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        return 1.0 - iou\n",
    "\n",
    "\n",
    "class MultiTaskECGLoss(nn.Module):\n",
    "    \"\"\"Combined loss for multi-task ECG model\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 w_seg: float = 1.0,\n",
    "                 w_det: float = 1.0,\n",
    "                 w_sig: float = 2.0,\n",
    "                 seg_loss_type: str = 'dice'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_seg = w_seg\n",
    "        self.w_det = w_det\n",
    "        self.w_sig = w_sig\n",
    "\n",
    "        # Segmentation loss\n",
    "        if seg_loss_type == 'dice':\n",
    "            self.seg_loss = DiceLoss()\n",
    "        else:\n",
    "            self.seg_loss = JaccardLoss()\n",
    "\n",
    "        # Detection losses\n",
    "        self.bbox_loss = nn.SmoothL1Loss()  # IoU-based or L1 for bbox regression\n",
    "        self.confidence_loss = nn.BCELoss()  # Binary cross-entropy for confidence\n",
    "\n",
    "        # Signal regression loss\n",
    "        self.signal_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: Dict with keys 'segmentation', 'bboxes', 'confidences', 'signal_traces'\n",
    "            targets: Dict with same keys containing ground truth\n",
    "\n",
    "        Returns:\n",
    "            Total loss and breakdown of components\n",
    "        \"\"\"\n",
    "        loss_dict = {}\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Segmentation loss\n",
    "        if 'segmentation' in predictions and 'segmentation' in targets:\n",
    "            seg_loss = self.seg_loss(predictions['segmentation'], targets['segmentation'])\n",
    "            loss_dict['seg_loss'] = seg_loss.item()\n",
    "            total_loss += self.w_seg * seg_loss\n",
    "\n",
    "        # Detection losses (bbox + confidence)\n",
    "        if 'bboxes' in predictions and 'bboxes' in targets:\n",
    "            bbox_loss = self.bbox_loss(predictions['bboxes'], targets['bboxes'])\n",
    "            loss_dict['bbox_loss'] = bbox_loss.item()\n",
    "            total_loss += self.w_det * bbox_loss\n",
    "\n",
    "        if 'confidences' in predictions and 'confidences' in targets:\n",
    "            conf_loss = self.confidence_loss(predictions['confidences'], targets['confidences'])\n",
    "            loss_dict['conf_loss'] = conf_loss.item()\n",
    "            total_loss += self.w_det * conf_loss\n",
    "\n",
    "        # Signal regression loss\n",
    "        if 'signal_traces' in predictions and 'signal_traces' in targets:\n",
    "            sig_loss = self.signal_loss(predictions['signal_traces'], targets['signal_traces'])\n",
    "            loss_dict['sig_loss'] = sig_loss.item()\n",
    "            total_loss += self.w_sig * sig_loss\n",
    "\n",
    "        loss_dict['total_loss'] = total_loss.item()\n",
    "\n",
    "        return total_loss, loss_dict\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e78f6",
   "metadata": {},
   "source": [
    "## ECGTrainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de70009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class ECGTrainer:\n",
    "    \"\"\"Training and evaluation loop for multi-task ECG model\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 device: torch.device,\n",
    "                 learning_rate: float = 1e-4,\n",
    "                 weight_decay: float = 1e-5):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = optim.Adam(model.parameters(),\n",
    "                                   lr=learning_rate,\n",
    "                                   weight_decay=weight_decay)\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=3\n",
    "        )\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = MultiTaskECGLoss(w_seg=1.0, w_det=1.0, w_sig=2.0)\n",
    "\n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'train_seg_loss': [],\n",
    "            'train_bbox_loss': [],\n",
    "            'train_sig_loss': []\n",
    "        }\n",
    "\n",
    "    def train_epoch(self, train_loader: DataLoader) -> Dict:\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        loss_breakdown = {\n",
    "            'seg_loss': 0.0,\n",
    "            'bbox_loss': 0.0,\n",
    "            'conf_loss': 0.0,\n",
    "            'sig_loss': 0.0\n",
    "        }\n",
    "\n",
    "        pbar = tqdm(train_loader, desc='Training', leave=False)\n",
    "\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            images = batch['image'].to(self.device)\n",
    "            targets = {\n",
    "                'segmentation': batch.get('segmentation_mask', None),\n",
    "                'bboxes': batch.get('bboxes', None),\n",
    "                'confidences': batch.get('confidences', None),\n",
    "                'signal_traces': batch.get('signal_traces', None)\n",
    "            }\n",
    "\n",
    "            # Move targets to device if they exist\n",
    "            targets = {k: v.to(self.device) if v is not None else None\n",
    "                      for k, v in targets.items()}\n",
    "\n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            predictions = self.model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss, loss_dict = self.criterion(predictions, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Accumulate losses\n",
    "            epoch_loss += loss.item()\n",
    "            for key in loss_breakdown:\n",
    "                if key in loss_dict:\n",
    "                    loss_breakdown[key] += loss_dict[key]\n",
    "\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        # Average losses\n",
    "        n_batches = len(train_loader)\n",
    "        epoch_loss /= n_batches\n",
    "        for key in loss_breakdown:\n",
    "            loss_breakdown[key] /= n_batches\n",
    "\n",
    "        return epoch_loss, loss_breakdown\n",
    "\n",
    "    def validate(self, val_loader: DataLoader) -> float:\n",
    "        \"\"\"Validate model\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc='Validation', leave=False)\n",
    "\n",
    "            for batch in pbar:\n",
    "                images = batch['image'].to(self.device)\n",
    "                targets = {\n",
    "                    'segmentation': batch.get('segmentation_mask', None),\n",
    "                    'bboxes': batch.get('bboxes', None),\n",
    "                    'confidences': batch.get('confidences', None),\n",
    "                    'signal_traces': batch.get('signal_traces', None)\n",
    "                }\n",
    "\n",
    "                targets = {k: v.to(self.device) if v is not None else None\n",
    "                          for k, v in targets.items()}\n",
    "\n",
    "                predictions = self.model(images)\n",
    "                loss, _ = self.criterion(predictions, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                pbar.set_postfix({'val_loss': loss.item()})\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def fit(self,\n",
    "            train_loader: DataLoader,\n",
    "            val_loader: Optional[DataLoader] = None,\n",
    "            epochs: int = 10):\n",
    "        \"\"\"\n",
    "        Train model for specified number of epochs.\n",
    "        \"\"\"\n",
    "        print(f\"Starting training for {epochs} epochs...\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "            # Train\n",
    "            train_loss, loss_breakdown = self.train_epoch(train_loader)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "\n",
    "            for key in loss_breakdown:\n",
    "                if key in self.history:\n",
    "                    self.history[key].append(loss_breakdown[key])\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.6f}\")\n",
    "            print(f\"  Seg Loss: {loss_breakdown.get('seg_loss', 0):.6f}\")\n",
    "            print(f\"  BBox Loss: {loss_breakdown.get('bbox_loss', 0):.6f}\")\n",
    "            print(f\"  Signal Loss: {loss_breakdown.get('sig_loss', 0):.6f}\")\n",
    "\n",
    "            # Validate\n",
    "            if val_loader is not None:\n",
    "                val_loss = self.validate(val_loader)\n",
    "                self.history['val_loss'].append(val_loss)\n",
    "                print(f\"Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "                # LR scheduling\n",
    "                self.scheduler.step(val_loss)\n",
    "\n",
    "        print(\"Training completed!\")\n",
    "\n",
    "        return self.history\n",
    "\n",
    "    def save_checkpoint(self, save_path: str):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'history': self.history\n",
    "        }\n",
    "        torch.save(checkpoint, save_path)\n",
    "        print(f\"Checkpoint saved to {save_path}\")\n",
    "\n",
    "    def load_checkpoint(self, load_path: str):\n",
    "        \"\"\"Load model checkpoint\"\"\"\n",
    "        checkpoint = torch.load(load_path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.history = checkpoint.get('history', self.history)\n",
    "        print(f\"Checkpoint loaded from {load_path}\")\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb146478",
   "metadata": {},
   "source": [
    "## SNRMetric Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0423e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class SNRMetric:\n",
    "    \"\"\"\n",
    "    Calculate modified Signal-to-Noise Ratio (SNR) metric for ECG evaluation.\n",
    "\n",
    "    The SNR metric compares predicted ECG signals to ground truth with:\n",
    "    - Optimal time shift alignment (up to 0.2 s)\n",
    "    - Vertical shift removal\n",
    "    - Per-lead calculation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampling_rate: float = 500.0, max_time_shift: float = 0.2):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.max_time_shift = max_time_shift\n",
    "        self.max_lag = int(max_time_shift * sampling_rate)\n",
    "\n",
    "    def find_optimal_time_shift(self,\n",
    "                               predicted: np.ndarray,\n",
    "                               ground_truth: np.ndarray) -> Tuple[float, int]:\n",
    "        \"\"\"\n",
    "        Find optimal time shift using cross-correlation.\n",
    "\n",
    "        Args:\n",
    "            predicted: Predicted signal (1D array)\n",
    "            ground_truth: Ground truth signal (1D array)\n",
    "\n",
    "        Returns:\n",
    "            optimal_lag: Optimal lag in samples\n",
    "            correlation: Maximum correlation value\n",
    "        \"\"\"\n",
    "        if len(predicted) < 2 or len(ground_truth) < 2:\n",
    "            return 0, 0.0\n",
    "\n",
    "        # Pad to same length if necessary\n",
    "        max_len = max(len(predicted), len(ground_truth))\n",
    "        pred_padded = np.pad(predicted, (0, max_len - len(predicted)), mode='constant')\n",
    "        gt_padded = np.pad(ground_truth, (0, max_len - len(ground_truth)), mode='constant')\n",
    "\n",
    "        # Cross-correlation\n",
    "        cross_corr = signal.correlate(pred_padded, gt_padded, mode='same')\n",
    "\n",
    "        # Find peak within allowed lag range\n",
    "        center = len(cross_corr) // 2\n",
    "        search_start = max(0, center - self.max_lag)\n",
    "        search_end = min(len(cross_corr), center + self.max_lag)\n",
    "\n",
    "        lag_idx = search_start + np.argmax(cross_corr[search_start:search_end])\n",
    "        optimal_lag = lag_idx - center\n",
    "        max_corr = cross_corr[lag_idx]\n",
    "\n",
    "        return optimal_lag, max_corr\n",
    "\n",
    "    def align_signals(self,\n",
    "                     predicted: np.ndarray,\n",
    "                     ground_truth: np.ndarray,\n",
    "                     lag: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Align signals using time shift and remove vertical offset.\n",
    "\n",
    "        Args:\n",
    "            predicted: Predicted signal\n",
    "            ground_truth: Ground truth signal\n",
    "            lag: Time shift in samples\n",
    "\n",
    "        Returns:\n",
    "            aligned_pred, aligned_gt: Aligned signals\n",
    "        \"\"\"\n",
    "        # Apply time shift\n",
    "        if lag > 0:\n",
    "            aligned_pred = np.roll(predicted, lag)\n",
    "        elif lag < 0:\n",
    "            aligned_pred = np.roll(predicted, lag)\n",
    "        else:\n",
    "            aligned_pred = predicted.copy()\n",
    "\n",
    "        # Trim to common length\n",
    "        min_len = min(len(aligned_pred), len(ground_truth))\n",
    "        aligned_pred = aligned_pred[:min_len]\n",
    "        aligned_gt = ground_truth[:min_len]\n",
    "\n",
    "        # Remove vertical shift (DC offset)\n",
    "        vertical_shift = np.mean(aligned_pred) - np.mean(aligned_gt)\n",
    "        aligned_pred = aligned_pred - vertical_shift\n",
    "\n",
    "        return aligned_pred, aligned_gt\n",
    "\n",
    "    def calculate_snr(self,\n",
    "                     predicted: np.ndarray,\n",
    "                     ground_truth: np.ndarray,\n",
    "                     find_shift: bool = True) -> float:\n",
    "        \"\"\"\n",
    "        Calculate modified SNR (dB) between predicted and ground truth.\n",
    "\n",
    "        SNR (dB) = 10 * log10(P_signal / P_noise)\n",
    "               = 10 * log10(P_truth / P_error)\n",
    "\n",
    "        Args:\n",
    "            predicted: Predicted signal\n",
    "            ground_truth: Ground truth signal\n",
    "            find_shift: Whether to find optimal time shift\n",
    "\n",
    "        Returns:\n",
    "            snr_db: SNR in dB (higher is better)\n",
    "        \"\"\"\n",
    "        if len(predicted) == 0 or len(ground_truth) == 0:\n",
    "            return -np.inf\n",
    "\n",
    "        # Find optimal alignment if enabled\n",
    "        if find_shift:\n",
    "            optimal_lag, _ = self.find_optimal_time_shift(predicted, ground_truth)\n",
    "        else:\n",
    "            optimal_lag = 0\n",
    "\n",
    "        # Align signals\n",
    "        aligned_pred, aligned_gt = self.align_signals(predicted, ground_truth, optimal_lag)\n",
    "\n",
    "        if len(aligned_gt) == 0:\n",
    "            return -np.inf\n",
    "\n",
    "        # Calculate power\n",
    "        signal_power = np.mean(aligned_gt ** 2)  # Power of ground truth\n",
    "        error = aligned_pred - aligned_gt\n",
    "        noise_power = np.mean(error ** 2)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if noise_power < 1e-10:\n",
    "            snr_db = np.inf if signal_power > 1e-10 else 0.0\n",
    "        else:\n",
    "            snr_db = 10.0 * np.log10(signal_power / noise_power)\n",
    "\n",
    "        return snr_db\n",
    "\n",
    "    def calculate_multipart_snr(self,\n",
    "                               predicted_leads: Dict[str, np.ndarray],\n",
    "                               ground_truth_leads: Dict[str, np.ndarray]) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate SNR for all 12 leads and aggregate statistics.\n",
    "\n",
    "        Args:\n",
    "            predicted_leads: Dict with lead names, signal arrays\n",
    "            ground_truth_leads: Dict with lead names, signal arrays\n",
    "\n",
    "        Returns:\n",
    "            Dict with per-lead SNR, mean SNR, min SNR, etc.\n",
    "        \"\"\"\n",
    "        snr_per_lead = {}\n",
    "        valid_snrs = []\n",
    "\n",
    "        for lead_name in ground_truth_leads.keys():\n",
    "            if lead_name in predicted_leads:\n",
    "                pred = predicted_leads[lead_name]\n",
    "                truth = ground_truth_leads[lead_name]\n",
    "\n",
    "                if len(pred) > 0 and len(truth) > 0:\n",
    "                    snr = self.calculate_snr(pred, truth, find_shift=True)\n",
    "                    snr_per_lead[lead_name] = snr\n",
    "\n",
    "                    if np.isfinite(snr):\n",
    "                        valid_snrs.append(snr)\n",
    "                else:\n",
    "                    snr_per_lead[lead_name] = -np.inf\n",
    "\n",
    "        # Aggregate statistics\n",
    "        results = {\n",
    "            'per_lead': snr_per_lead,\n",
    "            'mean_snr': np.mean(valid_snrs) if valid_snrs else -np.inf,\n",
    "            'median_snr': np.median(valid_snrs) if valid_snrs else -np.inf,\n",
    "            'min_snr': np.min(valid_snrs) if valid_snrs else -np.inf,\n",
    "            'max_snr': np.max(valid_snrs) if valid_snrs else -np.inf,\n",
    "            'std_snr': np.std(valid_snrs) if valid_snrs else 0.0,\n",
    "            'num_valid_leads': len(valid_snrs)\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def print_snr_report(self, snr_results: Dict):\n",
    "        \"\"\"Pretty print SNR evaluation report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SNR EVALUATION REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Mean SNR (12 leads): {snr_results['mean_snr']:.2f} dB\")\n",
    "        print(f\"Median SNR: {snr_results['median_snr']:.2f} dB\")\n",
    "        print(f\"Min SNR: {snr_results['min_snr']:.2f} dB\")\n",
    "        print(f\"Max SNR: {snr_results['max_snr']:.2f} dB\")\n",
    "        print(f\"Std Dev: {snr_results['std_snr']:.2f} dB\")\n",
    "        print(f\"Valid Leads: {snr_results['num_valid_leads']}/12\")\n",
    "        print(\"\\nPer-Lead SNR (dB):\")\n",
    "        print(\"-\" * 60)\n",
    "        for lead_name, snr_val in sorted(snr_results['per_lead'].items()):\n",
    "            status = \"âœ“\" if np.isfinite(snr_val) else \"âœ—\"\n",
    "            print(f\"  Lead {lead_name:4s}: {snr_val:8.2f} {status}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecb7f7",
   "metadata": {},
   "source": [
    "## ECGInferencePipeline Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9dd1616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class ECGInferencePipeline:\n",
    "    \"\"\"\n",
    "    End-to-end inference pipeline integrating all phases:\n",
    "    1. Image preprocessing and artifact correction\n",
    "    2. Lead detection and deskewing\n",
    "    3. Signal trace extraction\n",
    "    4. Calibration and physical unit conversion\n",
    "    5. Resampling to fixed sampling rate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 device: torch.device,\n",
    "                 sampling_rate: float = 500.0):\n",
    "        self.model = model.eval()\n",
    "        self.device = device\n",
    "        self.sampling_rate = sampling_rate\n",
    "\n",
    "        # Initialize components\n",
    "        self.data_loader = ECGDataLoader(image_dir='', csv_dir='',\n",
    "                                        target_size=(512, 1024),\n",
    "                                        sampling_rate=sampling_rate)\n",
    "        self.grid_filter = GridAndNoiseFilter()\n",
    "        self.lead_localizer = LeadLocalizationAndDeskew()\n",
    "        self.trace_extractor = SignalTraceExtractor(centerline_method='dynamic_programming')\n",
    "        self.calibrator = CalibrationAndScaling()\n",
    "        self.resampler = TimeSeriesResampler(target_sampling_rate=sampling_rate)\n",
    "        self.snr_calculator = SNRMetric(sampling_rate=sampling_rate)\n",
    "\n",
    "    def process_single_image(self, image_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Process a single ECG image through the complete pipeline.\n",
    "\n",
    "        Args:\n",
    "            image_path: Path to ECG image (JPEG/PNG)\n",
    "\n",
    "        Returns:\n",
    "            Dict with extracted signals and metadata\n",
    "        \"\"\"\n",
    "        # Load and preprocess image\n",
    "        image = self.data_loader.load_image(image_path)\n",
    "        image_normalized = self.data_loader.normalize_image(image)\n",
    "\n",
    "        # Artifact correction - filter grid and noise\n",
    "        signal_mask = self.grid_filter.filter_grid_opencv(image_normalized)\n",
    "\n",
    "        # Deskew image\n",
    "        deskewed_image, rotation_angle = self.lead_localizer.deskew_image(\n",
    "            image_normalized, rotation_angle=None\n",
    "        )\n",
    "\n",
    "        # Re-extract signal mask from deskewed image\n",
    "        signal_mask = self.grid_filter.filter_grid_opencv(deskewed_image)\n",
    "\n",
    "        # Detect lead bounding boxes\n",
    "        lead_bboxes = self.lead_localizer.detect_lead_bboxes(signal_mask, num_leads=12)\n",
    "\n",
    "        # Detect calibration marks\n",
    "        calib_info = self.lead_localizer.detect_calibration_marks(deskewed_image)\n",
    "\n",
    "        # Estimate calibration factors\n",
    "        calibration = self.calibrator.estimate_calibration_factors(deskewed_image,\n",
    "                                                                   self.sampling_rate)\n",
    "\n",
    "        # Extract traces for each lead\n",
    "        traces = {}\n",
    "        for i, bbox in enumerate(lead_bboxes):\n",
    "            trace = self.trace_extractor.extract_trace_dynamic_programming(\n",
    "                signal_mask, bbox\n",
    "            )\n",
    "\n",
    "            if len(trace) > 0:\n",
    "                trace = self.trace_extractor.smooth_trace(trace)\n",
    "                traces[f'Lead_{i}'] = trace\n",
    "\n",
    "        # Convert to physical units\n",
    "        physical_traces = self.calibrator.pixel_to_physical(traces, calibration,\n",
    "                                                            deskewed_image.shape[1])\n",
    "\n",
    "        # Resample to fixed sampling rate\n",
    "        resampled_leads = self.resampler.resample_all_leads(physical_traces, method='cubic')\n",
    "\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'rotation_angle': rotation_angle,\n",
    "            'calibration': calibration,\n",
    "            'num_leads_detected': len(lead_bboxes),\n",
    "            'lead_bboxes': lead_bboxes,\n",
    "            'calibration_marks': calib_info,\n",
    "            'pixel_traces': traces,\n",
    "            'physical_traces': physical_traces,\n",
    "            'resampled_signals': resampled_leads,\n",
    "            'signal_mask': signal_mask,\n",
    "            'deskewed_image': deskewed_image\n",
    "        }\n",
    "\n",
    "    def process_batch(self, image_paths: List[str]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Process a batch of ECG images.\n",
    "\n",
    "        Args:\n",
    "            image_paths: List of paths to ECG images\n",
    "\n",
    "        Returns:\n",
    "            List of result dicts\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        pbar = tqdm(image_paths, desc='Processing ECG images')\n",
    "        for img_path in pbar:\n",
    "            try:\n",
    "                result = self.process_single_image(img_path)\n",
    "                results.append(result)\n",
    "                pbar.set_postfix({'leads': result['num_leads_detected']})\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                results.append({\n",
    "                    'image_path': img_path,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def evaluate_with_ground_truth(self,\n",
    "                                   image_paths: List[str],\n",
    "                                   ground_truth_csvs: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Process images and evaluate SNR against ground truth.\n",
    "\n",
    "        Args:\n",
    "            image_paths: List of ECG image paths\n",
    "            ground_truth_csvs: List of ground truth CSV paths\n",
    "\n",
    "        Returns:\n",
    "            Dict with SNR statistics and per-sample results\n",
    "        \"\"\"\n",
    "        all_snrs = []\n",
    "        sample_results = []\n",
    "\n",
    "        for img_path, csv_path in zip(image_paths, ground_truth_csvs):\n",
    "            # Process image\n",
    "            try:\n",
    "                result = self.process_single_image(img_path)\n",
    "\n",
    "                # Load ground truth\n",
    "                gt_data = self.data_loader.load_ground_truth(csv_path)\n",
    "\n",
    "                # Ensure same format\n",
    "                gt_leads = {}\n",
    "                for lead_name, values in gt_data['leads'].items():\n",
    "                    if len(values) > 0:\n",
    "                        gt_leads[f'Lead_{lead_name}'] = values\n",
    "\n",
    "                # Calculate SNR\n",
    "                snr_result = self.snr_calculator.calculate_multipart_snr(\n",
    "                    result['resampled_signals'],\n",
    "                    gt_leads\n",
    "                )\n",
    "\n",
    "                all_snrs.append(snr_result['mean_snr'])\n",
    "                sample_results.append({\n",
    "                    'image': img_path,\n",
    "                    'snr_result': snr_result\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating {img_path}: {e}\")\n",
    "\n",
    "        # Aggregate statistics\n",
    "        aggregated = {\n",
    "            'num_samples': len(sample_results),\n",
    "            'mean_snr_overall': np.mean(all_snrs) if all_snrs else -np.inf,\n",
    "            'std_snr_overall': np.std(all_snrs) if all_snrs else 0.0,\n",
    "            'sample_results': sample_results\n",
    "        }\n",
    "\n",
    "        return aggregated\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b215b8",
   "metadata": {},
   "source": [
    "## ArtifactRobustnessTest Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e9c1f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All classes and functions defined successfully!\n",
      "✓ ECGDataLoader defined\n",
      "\n",
      "✓ ECGDataLoader defined\n"
     ]
    }
   ],
   "source": [
    "class ArtifactRobustnessTest:\n",
    "    \"\"\"\n",
    "    Test pipeline robustness to common imaging artifacts:\n",
    "    - Rotation\n",
    "    - Blur\n",
    "    - Noise\n",
    "    - Grid distortions\n",
    "    - Compression artifacts\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipeline: ECGInferencePipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.test_results = {}\n",
    "\n",
    "    def apply_rotation(self, image: np.ndarray, angle: float) -> np.ndarray:\n",
    "        \"\"\"Apply rotation to image\"\"\"\n",
    "        h, w = image.shape\n",
    "        center = (w / 2, h / 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, rotation_matrix, (w, h),\n",
    "                                borderMode=cv2.BORDER_REPLICATE)\n",
    "        return rotated\n",
    "\n",
    "    def apply_blur(self, image: np.ndarray, kernel_size: int = 5) -> np.ndarray:\n",
    "        \"\"\"Apply Gaussian blur\"\"\"\n",
    "        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 1.0)\n",
    "\n",
    "    def apply_noise(self, image: np.ndarray, std: float = 0.05) -> np.ndarray:\n",
    "        \"\"\"Add Gaussian noise\"\"\"\n",
    "        noise = np.random.normal(0, std, image.shape)\n",
    "        return np.clip(image + noise, 0, 1)\n",
    "\n",
    "    def apply_compression(self, image: np.ndarray, quality: int = 50) -> np.ndarray:\n",
    "        \"\"\"Simulate JPEG compression artifacts\"\"\"\n",
    "        # Convert to uint8, encode as JPEG, decode\n",
    "        img_uint8 = (image * 255).astype(np.uint8)\n",
    "        success, encoded = cv2.imencode('.jpg', img_uint8,\n",
    "                                       [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "        if success:\n",
    "            decoded = cv2.imdecode(encoded, cv2.IMREAD_GRAYSCALE)\n",
    "            return decoded.astype(np.float32) / 255.0\n",
    "        return image\n",
    "\n",
    "    def apply_contrast_change(self, image: np.ndarray, alpha: float = 1.5) -> np.ndarray:\n",
    "        \"\"\"Apply contrast stretching\"\"\"\n",
    "        return np.clip(image * alpha, 0, 1)\n",
    "\n",
    "    def test_rotation_robustness(self,\n",
    "                                image: np.ndarray,\n",
    "                                angles: List[float] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Test robustness to rotation artifacts.\n",
    "        Angles in degrees.\n",
    "        \"\"\"\n",
    "        if angles is None:\n",
    "            angles = [-10, -5, 0, 5, 10, 15]\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        print(\"\\nTesting Rotation Robustness...\")\n",
    "        for angle in angles:\n",
    "            try:\n",
    "                rotated = self.apply_rotation(image, angle)\n",
    "\n",
    "                # Verify deskewing works\n",
    "                lead_localizer = LeadLocalizationAndDeskew()\n",
    "                deskewed, estimated_angle = lead_localizer.deskew_image(rotated)\n",
    "\n",
    "                angle_error = abs(estimated_angle - (-angle))\n",
    "                results[f'{angle:+.0f}Â°'] = {\n",
    "                    'estimated_angle': estimated_angle,\n",
    "                    'error': angle_error\n",
    "                }\n",
    "                print(f\"  Angle {angle:+.0f}Â° -> Est: {estimated_angle:+.1f}Â° (Error: {angle_error:.2f}Â°)\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Angle {angle:+.0f}Â°: Failed - {e}\")\n",
    "                results[f'{angle:+.0f}Â°'] = {'error': str(e)}\n",
    "\n",
    "        self.test_results['rotation'] = results\n",
    "        return results\n",
    "\n",
    "    def test_blur_robustness(self,\n",
    "                            image: np.ndarray,\n",
    "                            kernel_sizes: List[int] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Test robustness to blur artifacts.\n",
    "        \"\"\"\n",
    "        if kernel_sizes is None:\n",
    "            kernel_sizes = [3, 5, 7, 11]\n",
    "\n",
    "        results = {}\n",
    "        grid_filter = GridAndNoiseFilter()\n",
    "\n",
    "        print(\"\\nTesting Blur Robustness...\")\n",
    "        for kernel_size in kernel_sizes:\n",
    "            try:\n",
    "                blurred = self.apply_blur(image, kernel_size)\n",
    "\n",
    "                # Test signal extraction\n",
    "                mask = grid_filter.filter_grid_opencv(blurred)\n",
    "                signal_preserved = mask.sum() / image.size\n",
    "\n",
    "                results[f'Kernel {kernel_size}x{kernel_size}'] = {\n",
    "                    'signal_preserved_ratio': float(signal_preserved),\n",
    "                    'status': 'OK'\n",
    "                }\n",
    "                print(f\"  Kernel {kernel_size}x{kernel_size}: {signal_preserved*100:.1f}% signal preserved\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Kernel {kernel_size}x{kernel_size}: Failed - {e}\")\n",
    "                results[f'Kernel {kernel_size}x{kernel_size}'] = {'error': str(e)}\n",
    "\n",
    "        self.test_results['blur'] = results\n",
    "        return results\n",
    "\n",
    "    def test_noise_robustness(self,\n",
    "                             image: np.ndarray,\n",
    "                             noise_levels: List[float] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Test robustness to additive Gaussian noise.\n",
    "        \"\"\"\n",
    "        if noise_levels is None:\n",
    "            noise_levels = [0.01, 0.03, 0.05, 0.1]\n",
    "\n",
    "        results = {}\n",
    "        grid_filter = GridAndNoiseFilter()\n",
    "\n",
    "        print(\"\\nTesting Noise Robustness...\")\n",
    "        for std in noise_levels:\n",
    "            try:\n",
    "                noisy = self.apply_noise(image, std)\n",
    "\n",
    "                # Test signal extraction\n",
    "                mask = grid_filter.filter_grid_opencv(noisy)\n",
    "                signal_preserved = mask.sum() / image.size\n",
    "\n",
    "                results[f'Std {std:.3f}'] = {\n",
    "                    'signal_preserved_ratio': float(signal_preserved),\n",
    "                    'psnr': self._calculate_psnr(noisy, image),\n",
    "                    'status': 'OK'\n",
    "                }\n",
    "                psnr = self._calculate_psnr(noisy, image)\n",
    "                print(f\"  Noise Std {std:.3f}: {signal_preserved*100:.1f}% preserved, PSNR: {psnr:.2f} dB\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Noise Std {std:.3f}: Failed - {e}\")\n",
    "                results[f'Std {std:.3f}'] = {'error': str(e)}\n",
    "\n",
    "        self.test_results['noise'] = results\n",
    "        return results\n",
    "\n",
    "    def test_compression_robustness(self,\n",
    "                                   image: np.ndarray,\n",
    "                                   quality_levels: List[int] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Test robustness to JPEG compression.\n",
    "        \"\"\"\n",
    "        if quality_levels is None:\n",
    "            quality_levels = [95, 75, 50, 30]\n",
    "\n",
    "        results = {}\n",
    "        grid_filter = GridAndNoiseFilter()\n",
    "\n",
    "        print(\"\\nTesting Compression Robustness...\")\n",
    "        for quality in quality_levels:\n",
    "            try:\n",
    "                compressed = self.apply_compression(image, quality)\n",
    "\n",
    "                # Test signal extraction\n",
    "                mask = grid_filter.filter_grid_opencv(compressed)\n",
    "                signal_preserved = mask.sum() / image.size\n",
    "\n",
    "                results[f'Quality {quality}'] = {\n",
    "                    'signal_preserved_ratio': float(signal_preserved),\n",
    "                    'status': 'OK'\n",
    "                }\n",
    "                print(f\"  Quality {quality}: {signal_preserved*100:.1f}% signal preserved\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Quality {quality}: Failed - {e}\")\n",
    "                results[f'Quality {quality}'] = {'error': str(e)}\n",
    "\n",
    "        self.test_results['compression'] = results\n",
    "        return results\n",
    "\n",
    "    def test_combined_artifacts(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Test with multiple artifacts combined.\n",
    "        Simulates realistic conditions.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        grid_filter = GridAndNoiseFilter()\n",
    "        lead_localizer = LeadLocalizationAndDeskew()\n",
    "\n",
    "        print(\"\\nTesting Combined Artifacts...\")\n",
    "\n",
    "        # Scenario 1: Slight rotation + moderate noise\n",
    "        try:\n",
    "            img1 = self.apply_rotation(image, 3.0)\n",
    "            img1 = self.apply_noise(img1, 0.03)\n",
    "\n",
    "            mask = grid_filter.filter_grid_opencv(img1)\n",
    "            deskewed, angle = lead_localizer.deskew_image(img1)\n",
    "\n",
    "            results['Rotation(3Â°) + Noise(0.03)'] = {\n",
    "                'angle_error': abs(angle - (-3.0)),\n",
    "                'signal_ratio': float(mask.sum() / image.size),\n",
    "                'status': 'OK'\n",
    "            }\n",
    "            print(f\"  Rot+Noise: Angle error {abs(angle+3):.2f}Â°, Signal {mask.sum()/image.size*100:.1f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Rot+Noise: Failed - {e}\")\n",
    "            results['Rotation(3Â°) + Noise(0.03)'] = {'error': str(e)}\n",
    "\n",
    "        # Scenario 2: Blur + compression\n",
    "        try:\n",
    "            img2 = self.apply_blur(image, 5)\n",
    "            img2 = self.apply_compression(img2, 60)\n",
    "\n",
    "            mask = grid_filter.filter_grid_opencv(img2)\n",
    "            results['Blur(5x5) + Compression(60)'] = {\n",
    "                'signal_ratio': float(mask.sum() / image.size),\n",
    "                'status': 'OK'\n",
    "            }\n",
    "            print(f\"  Blur+Comp: Signal {mask.sum()/image.size*100:.1f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Blur+Comp: Failed - {e}\")\n",
    "            results['Blur(5x5) + Compression(60)'] = {'error': str(e)}\n",
    "\n",
    "        # Scenario 3: High noise + contrast change\n",
    "        try:\n",
    "            img3 = self.apply_noise(image, 0.05)\n",
    "            img3 = self.apply_contrast_change(img3, 1.3)\n",
    "\n",
    "            mask = grid_filter.filter_grid_opencv(img3)\n",
    "            results['HighNoise(0.05) + Contrast(1.3)'] = {\n",
    "                'signal_ratio': float(mask.sum() / image.size),\n",
    "                'status': 'OK'\n",
    "            }\n",
    "            print(f\"  HighNoise+Contrast: Signal {mask.sum()/image.size*100:.1f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"  HighNoise+Contrast: Failed - {e}\")\n",
    "            results['HighNoise(0.05) + Contrast(1.3)'] = {'error': str(e)}\n",
    "\n",
    "        self.test_results['combined'] = results\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_psnr(img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "        \"\"\"Calculate PSNR between two images\"\"\"\n",
    "        mse = np.mean((img1 - img2) ** 2)\n",
    "        if mse == 0:\n",
    "            return np.inf\n",
    "        max_val = 1.0\n",
    "        psnr = 20 * np.log10(max_val / np.sqrt(mse))\n",
    "        return psnr\n",
    "\n",
    "    def print_test_summary(self):\n",
    "        \"\"\"Print summary of all robustness tests\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ROBUSTNESS TEST SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        for test_name, results in self.test_results.items():\n",
    "            print(f\"\\n{test_name.upper()} TEST:\")\n",
    "            print(\"-\" * 70)\n",
    "            for scenario, result in results.items():\n",
    "                if isinstance(result, dict) and 'error' not in result:\n",
    "                    print(f\"  {scenario}: PASS\")\n",
    "                else:\n",
    "                    print(f\"  {scenario}: FAIL - {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "\n",
    "def generate_synthetic_ecg_image(height: int = 512,\n",
    "                                width: int = 1024,\n",
    "                                num_leads: int = 3,\n",
    "                                add_grid: bool = True,\n",
    "                                add_noise: bool = True,\n",
    "                                rotation: float = 0.0) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Generate a synthetic ECG image for testing.\n",
    "\n",
    "    Args:\n",
    "        height, width: Image dimensions\n",
    "        num_leads: Number of ECG leads to draw\n",
    "        add_grid: Whether to add background grid\n",
    "        add_noise: Whether to add noise\n",
    "        rotation: Rotation angle in degrees\n",
    "\n",
    "    Returns:\n",
    "        image: Synthetic ECG image (normalized to [0, 1])\n",
    "        metadata: Generation metadata\n",
    "    \"\"\"\n",
    "    # Initialize blank image\n",
    "    image = np.ones((height, width), dtype=np.float32)\n",
    "\n",
    "    # Add grid background if requested\n",
    "    if add_grid:\n",
    "        grid_spacing_major = 50\n",
    "        grid_spacing_minor = 10\n",
    "\n",
    "        # Major grid (dark lines)\n",
    "        for y in range(0, height, grid_spacing_major):\n",
    "            image[y:y+1, :] *= 0.9\n",
    "        for x in range(0, width, grid_spacing_major):\n",
    "            image[:, x:x+1] *= 0.9\n",
    "\n",
    "        # Minor grid (lighter lines)\n",
    "        for y in range(0, height, grid_spacing_minor):\n",
    "            if y % grid_spacing_major != 0:\n",
    "                image[y:y+1, :] *= 0.95\n",
    "        for x in range(0, width, grid_spacing_minor):\n",
    "            if x % grid_spacing_major != 0:\n",
    "                image[:, x:x+1] *= 0.95\n",
    "\n",
    "    # Draw ECG traces for each lead\n",
    "    traces = {}\n",
    "    lead_spacing = height // (num_leads + 1)\n",
    "\n",
    "    for lead_idx in range(num_leads):\n",
    "        y_center = (lead_idx + 1) * lead_spacing\n",
    "\n",
    "        # Generate realistic ECG waveform using sinusoids\n",
    "        x_vals = np.arange(width)\n",
    "\n",
    "        # Create composite waveform (P-QRS-T pattern)\n",
    "        waveform = np.zeros(width)\n",
    "\n",
    "        # P wave (small amplitude, early)\n",
    "        p_start, p_end = 50, 150\n",
    "        p_phase = 2 * np.pi * x_vals / 100\n",
    "        waveform[p_start:p_end] += 0.2 * np.sin(p_phase[p_start:p_end])\n",
    "\n",
    "        # QRS complex (large amplitude, middle)\n",
    "        qrs_start, qrs_end = 350, 450\n",
    "        qrs_phase = 2 * np.pi * x_vals / 50\n",
    "        waveform[qrs_start:qrs_end] += 0.8 * np.sin(qrs_phase[qrs_start:qrs_end])\n",
    "\n",
    "        # T wave (medium amplitude, late)\n",
    "        t_start, t_end = 550, 650\n",
    "        t_phase = 2 * np.pi * x_vals / 150\n",
    "        waveform[t_start:t_end] += 0.4 * np.sin(t_phase[t_start:t_end])\n",
    "\n",
    "        # Add some baseline wander\n",
    "        baseline = 0.1 * np.sin(2 * np.pi * x_vals / 200)\n",
    "        waveform += baseline\n",
    "\n",
    "        # Convert to pixel coordinates\n",
    "        y_pixels = y_center - waveform * 30  # Scale amplitude\n",
    "\n",
    "        # Draw the trace\n",
    "        for x in range(1, width):\n",
    "            y1 = int(y_pixels[x-1])\n",
    "            y2 = int(y_pixels[x])\n",
    "            cv2.line(image, (x-1, y1), (x, y2), 0.0, 2)\n",
    "\n",
    "        traces[f'lead_{lead_idx}'] = waveform\n",
    "\n",
    "    # Add noise if requested\n",
    "    if add_noise:\n",
    "        noise = np.random.normal(0, 0.02, image.shape)\n",
    "        image = np.clip(image + noise, 0, 1)\n",
    "\n",
    "    # Apply rotation if requested\n",
    "    if rotation != 0.0:\n",
    "        h, w = image.shape\n",
    "        center = (w / 2, h / 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, rotation, 1.0)\n",
    "        image = cv2.warpAffine(image, rotation_matrix, (w, h),\n",
    "                              borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    metadata = {\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'num_leads': num_leads,\n",
    "        'add_grid': add_grid,\n",
    "        'add_noise': add_noise,\n",
    "        'rotation': rotation,\n",
    "        'traces': traces\n",
    "    }\n",
    "\n",
    "    return image, metadata\n",
    "\n",
    "\n",
    "print(\"All classes and functions defined successfully!\")\n",
    "\n",
    "print(f\"✓ {class_name} defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e860df",
   "metadata": {},
   "source": [
    "## Complete Usage Example and Demo\n",
    "\n",
    "Configuration and initialization of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d199b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "✓ Model created with 27,662,912 parameters\n",
      "✓ Trainer initialized\n",
      "✓ Inference pipeline ready\n",
      "✓ Robustness tester initialized\n",
      "\n",
      "============================================================\n",
      "ECG PIPELINE FULLY FUNCTIONAL AND READY\n",
      "============================================================\n",
      "✓ Model created with 27,662,912 parameters\n",
      "✓ Trainer initialized\n",
      "✓ Inference pipeline ready\n",
      "✓ Robustness tester initialized\n",
      "\n",
      "============================================================\n",
      "ECG PIPELINE FULLY FUNCTIONAL AND READY\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Create model\n",
    "model = MultiTaskECGModel(\n",
    "    backbone=\"resnet34\",\n",
    "    num_leads=12,\n",
    "    sequence_length=1024,\n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ Model created with {total_params:,} parameters\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = ECGTrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    learning_rate=1e-4\n",
    ")\n",
    "print(\"✓ Trainer initialized\")\n",
    "\n",
    "# Create inference pipeline\n",
    "inference_pipeline = ECGInferencePipeline(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    sampling_rate=500.0\n",
    ")\n",
    "print(\"✓ Inference pipeline ready\")\n",
    "\n",
    "# Create robustness tester\n",
    "robustness_tester = ArtifactRobustnessTest(pipeline=inference_pipeline)\n",
    "print(\"✓ Robustness tester initialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ECG PIPELINE FULLY FUNCTIONAL AND READY\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
